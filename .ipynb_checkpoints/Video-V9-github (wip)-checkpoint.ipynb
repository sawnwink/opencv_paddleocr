{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2b0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "frameInterval=10\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "#POSE\n",
    "pose_estimator = []\n",
    "pose_estimator_dim = []\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "poses=['NOSE','LEFT_EYE_INNER','LEFT_EYE','LEFT_EYE_OUTER','RIGHT_EYE_INNER','RIGHT_EYE','RIGHT_EYE_OUTER','LEFT_EAR',\n",
    "       'RIGHT_EAR','MOUTH_LEFT','MOUTH_RIGHT','LEFT_SHOULDER','RIGHT_SHOULDER','LEFT_ELBOW','RIGHT_ELBOW','LEFT_WRIST',\n",
    "       'RIGHT_WRIST','LEFT_PINKY','RIGHT_PINKY','LEFT_INDEX','RIGHT_INDEX','LEFT_THUMB','RIGHT_THUMB','LEFT_HIP',\n",
    "       'RIGHT_HIP','LEFT_KNEE','RIGHT_KNEE','LEFT_ANKLE','RIGHT_ANKLE','LEFT_HEEL','RIGHT_HEEL','LEFT_FOOT_INDEX',\n",
    "       'RIGHT_FOOT_INDEX'\n",
    "      ]\n",
    "\n",
    "# YOLO\n",
    "with open('yolo-coco-data/coco.names') as f:\n",
    "    labels = [line.strip() for line in f]   \n",
    "\n",
    "\n",
    "network = cv2.dnn.readNetFromDarknet('yolo-coco-data/yolov3.cfg',\n",
    "                                     'yolo-coco-data/yolov3.weights')\n",
    "\n",
    "\n",
    "def compareDist(x,y):\n",
    "    # intializing points in numpy arrays \n",
    "    point1 = np.array(x) \n",
    "    point2 = np.array(y) \n",
    "    # calculating Euclidean distance \n",
    "    dist = np.linalg.norm(point1 - point2) \n",
    "    return dist\n",
    "\n",
    "def yolo(image,bounding_boxes,confidences,class_numbers):\n",
    "\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    probability_minimum = 0.5\n",
    "    threshold = 0.1\n",
    "    layers_names_all = network.getLayerNames()\n",
    "    layers_names_output = [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "                     swapRB=True, crop=False)\n",
    "\n",
    "    network.setInput(blob)\n",
    "    output_from_network = network.forward(layers_names_output)            \n",
    "            \n",
    "    for result in output_from_network:\n",
    "        for detected_objects in result:\n",
    "            scores = detected_objects[5:]\n",
    "            class_current = np.argmax(scores)\n",
    "            confidence_current = scores[class_current]\n",
    "            if confidence_current > probability_minimum:\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "                buffer=5\n",
    "                bounding_boxes.append([x_min-buffer, y_min-buffer, int(box_width)+2*buffer, int(box_height)+2*buffer])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
    "                               probability_minimum, threshold)\n",
    "    return results\n",
    "\n",
    "\n",
    "    \n",
    "def cropImage(img,x,y,w,h):\n",
    "    height, width, channels = img.shape \n",
    "    x_start=0\n",
    "    y_start=0\n",
    "    if x>0:\n",
    "        x_start=x\n",
    "    if y>0:\n",
    "        y_start=y    \n",
    "    crop_img = img[y_start:y+h, x_start:x+w]\n",
    "    return crop_img\n",
    "\n",
    "cap = cv2.VideoCapture('videos/StarsAlign.mp4')\n",
    "fwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "fheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (fwidth,fheight))\n",
    "\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "\n",
    "c=1\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    if (success):\n",
    "        if(c%frameInterval==0):\n",
    "\n",
    "            class_numbers = []\n",
    "            confidences = []\n",
    "            bounding_boxes = []\n",
    "\n",
    "            yolo_results=yolo(image,bounding_boxes,confidences,class_numbers)\n",
    "            width = image.shape[1]\n",
    "            height = image.shape[0]\n",
    "    \n",
    "            counter = 1\n",
    "            if len(yolo_results) > 0:\n",
    "                for i in yolo_results.flatten():\n",
    "                    if(labels[int(class_numbers[i])]=='person'):                            \n",
    "\n",
    "                        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "                        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "                        colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "                        temp_clone = image.copy()\n",
    "                        crop_img = cropImage(temp_clone,x_min,y_min, box_width , box_height )\n",
    "                        crop_img_width =crop_img.shape[1]\n",
    "                        crop_img_height=crop_img.shape[0]\n",
    "\n",
    "                        # SELECT POSE ESTIMATOR TO USE.\n",
    "                        selected_pose_idx=0\n",
    "                        if(len(pose_estimator)==0): \n",
    "                            pose = mp_pose.Pose(min_detection_confidence=0.6, min_tracking_confidence=0.6)\n",
    "                            pose_estimator.append(pose)    \n",
    "                            pose_estimator_dim.append([x_min, y_min, box_width, box_height])\n",
    "                            selected_pose_idx = len(pose_estimator)-1 # get max                                \n",
    "                        elif(counter>len(pose_estimator)):\n",
    "                            thresholdForNew = 100\n",
    "                            prev_high_score = 0\n",
    "                            selected_pose_idx_high =0\n",
    "                            prev_low_score = 1000000000\n",
    "                            selected_pose_idx_low =0\n",
    "                            pose_idx = 0\n",
    "                            for dim in pose_estimator_dim:\n",
    "                                score = compareDist(dim,[x_min, y_min, box_width, box_height])\n",
    "                                if(score > prev_high_score):\n",
    "                                    selected_pose_idx_high  =  pose_idx\n",
    "                                    prev_high_score = score\n",
    "                                if(score < prev_low_score):                                        \n",
    "                                    selected_pose_idx_low  =  pose_idx\n",
    "                                    prev_low_score = score\n",
    "                                pose_idx+=1\n",
    "                            if prev_high_score > thresholdForNew:\n",
    "                                pose = mp_pose.Pose(min_detection_confidence=0.6, min_tracking_confidence=0.6)\n",
    "                                pose_estimator.append(pose)    \n",
    "                                pose_estimator_dim.append([x_min, y_min, box_width, box_height])\n",
    "                                selected_pose_idx = len(pose_estimator)-1 # get max\n",
    "                            else:\n",
    "                                selected_pose_idx = selected_pose_idx_low\n",
    "                                pose_estimator_dim[selected_pose_idx]=[x_min, y_min, box_width, box_height]\n",
    "                        else:\n",
    "                            pose_idx = 0\n",
    "                            prev_score = 1000000000\n",
    "                            for dim in pose_estimator_dim:\n",
    "                                score = compareDist(dim,[x_min, y_min, box_width, box_height])\n",
    "                                if(score < prev_score):                                        \n",
    "                                    selected_pose_idx  =  pose_idx\n",
    "                                    prev_score = score   \n",
    "                                pose_idx+=1\n",
    "                            pose_estimator_dim[selected_pose_idx]=[x_min, y_min, box_width, box_height]\n",
    "  \n",
    "                        # load the correct estimator\n",
    "                        results = pose_estimator[selected_pose_idx].process(crop_img)\n",
    "\n",
    "                        # Draw YOLO boxes\n",
    "                        cv2.rectangle(image, (x_min, y_min),\n",
    "                                      (x_min + box_width, y_min + box_height),\n",
    "                                      colour_box_current, 5)\n",
    "\n",
    "                        # Draw Poses\n",
    "                        if(results.pose_landmarks):\n",
    "                            mp_drawing.draw_landmarks(\n",
    "                            crop_img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                            for p in poses:    \n",
    "                                newX = (x_min+results.pose_landmarks.landmark[mp_pose.PoseLandmark[p]].x*crop_img_width) /width\n",
    "                                newY = (y_min+results.pose_landmarks.landmark[mp_pose.PoseLandmark[p]].y*crop_img_height) /height\n",
    "                                results.pose_landmarks.landmark[mp_pose.PoseLandmark[p]].x = newX \n",
    "                                results.pose_landmarks.landmark[mp_pose.PoseLandmark[p]].y = newY\n",
    "\n",
    "                        \n",
    "                            mp_drawing.draw_landmarks(\n",
    "                                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)        \n",
    "\n",
    "                        # Incrementing counter\n",
    "                        counter += 1 \n",
    "            out.write(image)\n",
    "        c+=1   \n",
    "    else:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        break\n",
    "    \n",
    "pose.close()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e7241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
